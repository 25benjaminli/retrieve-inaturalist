{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "names = ['aphanizomenon', 'detritus', 'dolichospermum', 'microcystis', 'oscillatoria', 'water bubble', 'woronichinia']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy b_ds directory\n",
    "shutil.rmtree('b_ds_need_label')\n",
    "shutil.copytree('b_ds', 'b_ds_need_label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy b_ds directory\n",
    "shutil.rmtree('b_ds_need_label')\n",
    "shutil.copytree('b_ds', 'b_ds_need_label')\n",
    "\n",
    "# iterate over b_ds and add _background to the end of filenames\n",
    "excludes = ['anabaena']\n",
    "for split in os.listdir('b_ds_need_label'):\n",
    "    if split == 'train' or split == 'valid' or split == 'test':\n",
    "        for filename in os.listdir(f'b_ds_need_label/{split}/images'):\n",
    "            name_val, ext = os.path.splitext(filename)\n",
    "            if 'background' in name_val:\n",
    "                os.remove(f'b_ds_need_label/{split}/images/{filename}')\n",
    "                continue\n",
    "\n",
    "            docontinue = False\n",
    "            for exclude in excludes:\n",
    "                if exclude in name_val:\n",
    "                    docontinue = True\n",
    "                    os.remove(f'b_ds_need_label/{split}/images/{filename}')\n",
    "                    os.remove(f'b_ds_need_label/{split}/labels/{name_val}.txt')\n",
    "                    break\n",
    "            \n",
    "            if docontinue:\n",
    "                continue\n",
    "\n",
    "            if not 'original' in filename:\n",
    "                # delete the image and label\n",
    "                try:\n",
    "                    os.remove(f'b_ds_need_label/{split}/images/{filename}')\n",
    "                    os.remove(f'b_ds_need_label/{split}/labels/{name_val}.txt')\n",
    "                    continue\n",
    "                except:\n",
    "                    os.remove(f'b_ds_need_label/{split}/images/{filename}')\n",
    "            \n",
    "            b = False\n",
    "            for name in names:\n",
    "                if name in filename:\n",
    "                    b = True\n",
    "                    break\n",
    "            \n",
    "            if not b:\n",
    "                try:\n",
    "                    os.remove(f'b_ds_need_label/{split}/images/{filename}')\n",
    "                    os.remove(f'b_ds_need_label/{split}/labels/{name_val}.txt')\n",
    "                except:\n",
    "                    # otherwise, it might be incorrectly done\n",
    "                    print(name_val, ext)\n",
    "                    print(filename)\n",
    "                    os.remove(f'b_ds_need_label/{split}/images/{filename}')\n",
    "\n",
    "\n",
    "            # name, ext = os.path.splitext(filename)\n",
    "\n",
    "            # with open(f'b_ds_need_label/{split}/labels/{filename}', 'r') as f:\n",
    "            #     data = f.read()\n",
    "\n",
    "            #     if len(data) == 0: # we know it is background\n",
    "            #         os.rename(f'b_ds_need_label/{split}/images/{filename}', f'b_ds_need_label/{split}/images/{name}_background{ext}')\n",
    "                    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('b_ds_need_label/train/images')))\n",
    "print(len(os.listdir('b_ds_need_label/valid/images')))\n",
    "print(len(os.listdir('b_ds_need_label/test/images')))\n",
    "\n",
    "print(len(os.listdir('b_ds_need_label/train/labels')) + len(os.listdir('b_ds_need_label/valid/labels')) + len(os.listdir('b_ds_need_label/test/labels')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('licenses.json') as f:\n",
    "    licenses = json.load(f)\n",
    "\n",
    "cannot_use = set([])\n",
    "names = set([])\n",
    "for l, vals in licenses.items():\n",
    "    if l == 'null':\n",
    "        print(licenses[l])\n",
    "        for name, imgs in licenses[l].items():\n",
    "            names.add(name)\n",
    "            for img_name, url in imgs.items():\n",
    "                cannot_use.add(img_name)\n",
    "\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "tot = 0\n",
    "for split in os.listdir('b_ds'):\n",
    "    if split == 'test' or split == 'train' or split == 'valid':\n",
    "        print(split)\n",
    "        for img in os.listdir(f'b_ds/{split}/images'):\n",
    "            # rename image at this path to remove \"_jpg\"\n",
    "            # get index of \"_jpg\"\n",
    "            if 'oscillatoria' in img and 'original' in img:\n",
    "                x+=1\n",
    "            if 'medium' in img or 'small' in img:\n",
    "                y+=1\n",
    "            \n",
    "            tot+=1\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(tot)\n",
    "\n",
    "\n",
    "# TODO: remove all that are not originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def delete_all_folders():\n",
    "    shutil.rmtree(path + \"/combined_ds\")\n",
    "    shutil.rmtree(path + \"/org_ds\")\n",
    "    shutil.rmtree(path + \"/final_ds\")\n",
    "try:\n",
    "    delete_all_folders()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data.yaml from b_ds\n",
    "with open('b_ds/data.yaml', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# remove everything after \"roboflow\"\n",
    "data = data.split('roboflow')[0] # this will be the same...\n",
    "\n",
    "# get all names from data.yaml\n",
    "names = data.split('names: ')[1]\n",
    "\n",
    "# convert string names to list\n",
    "names = eval(names)\n",
    "print(names)\n",
    "\n",
    "# rewrite train, val, test to go to final_ds/{split}/images instead of ../{split}/images\n",
    "data = data.replace('../train/images', 'final_ds/train/images')\n",
    "data = data.replace('../valid/images', 'final_ds/valid/images')\n",
    "data = data.replace('../test/images', 'final_ds/test/images')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get names of all files in Bacteria Dataset\n",
    "# bacteria_file_names = []\n",
    "# splits = ['train', 'valid', 'test']\n",
    "# for folder in os.listdir(path + \"/Bacteria Dataset/Dataset-1\"):\n",
    "#     if os.path.isfile(folder) or not (folder in names):\n",
    "#         continue\n",
    "#     for file in os.listdir(path + \"/Bacteria Dataset/Dataset-1/\" + folder):\n",
    "#         if file == \".DS_Store\":\n",
    "#             continue\n",
    "        \n",
    "#         img = cv2.imread(path + \"/Bacteria Dataset/Dataset-1/\" + folder + \"/\" + file, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "#         # resize image to 320x320\n",
    "#         img = cv2.resize(img, (512, 512))\n",
    "#         # apply clahe\n",
    "#         clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#         img = clahe.apply(img)\n",
    "#         # save image\n",
    "#         cv2.imwrite(path + \"/bacteria_file_names/\" + file, img)\n",
    "\n",
    "# for folder in os.listdir(path + \"/Bacteria Dataset/Dataset-2\"):\n",
    "#     if os.path.isfile(folder) or not (folder in names):\n",
    "#         continue\n",
    "        \n",
    "#     for file in os.listdir(path + \"/Bacteria Dataset/Dataset-2/\" + folder):\n",
    "#         if file == \".DS_Store\":\n",
    "#             continue\n",
    "\n",
    "#         # grayscale\n",
    "        \n",
    "\n",
    "#         img = cv2.imread(path + \"/Bacteria Dataset/Dataset-2/\" + folder + \"/\" + file, cv2.IMREAD_GRAYSCALE)\n",
    "#         # resize image to 320x320\n",
    "#         img = cv2.resize(img, (512, 512))\n",
    "#         # apply clahe\n",
    "#         clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#         img = clahe.apply(img)\n",
    "#         # save image\n",
    "#         cv2.imwrite(path + \"/bacteria_file_names/\" + file, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(path + \"/bacteria_file_names\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_combined(exclude_classes = ['anabaena']):\n",
    "    splits = ['test', 'train', 'valid']\n",
    "\n",
    "    if os.path.exists(path + f\"/combined_ds\"):\n",
    "        shutil.rmtree(path + f\"/combined_ds\")\n",
    "    os.mkdir(path + f\"/combined_ds\")\n",
    "    os.mkdir(path + f\"/combined_ds/images\")\n",
    "    os.mkdir(path + f\"/combined_ds/labels\")\n",
    "\n",
    "    seen = []\n",
    "    for split in splits:\n",
    "        for img in os.listdir(f'{path}/b_ds/{split}/images'):\n",
    "            if len(exclude_classes) > 0:\n",
    "                for exclude_class in exclude_classes:\n",
    "                    if not exclude_class in img:\n",
    "                        curr_img = cv2.imread(f'{path}/b_ds/{split}/images/{img}')\n",
    "                        skip = False                        \n",
    "                        \n",
    "                        for seen_img in seen:\n",
    "                            if cv2.compare(seen_img, curr_img, cv2.CMP_EQ):\n",
    "                                print(f'{img} is a duplicate of {seen_img}')\n",
    "                                skip = True\n",
    "                                break\n",
    "                        \n",
    "                        seen.append(curr_img)\n",
    "                        shutil.copy(f'{path}/b_ds/{split}/images/{img}', f'{path}/combined_ds/images/{img}')\n",
    "            else:\n",
    "                shutil.copy(f'{path}/b_ds/{split}/images/{img}', f'{path}/combined_ds/images/{img}')\n",
    "        for label in os.listdir(f'{path}/b_ds/{split}/labels'):\n",
    "            if len(exclude_classes) > 0:\n",
    "                for exclude_class in exclude_classes:            \n",
    "                    if not exclude_class in label:\n",
    "                        shutil.copy(f'{path}/b_ds/{split}/labels/{label}', f'{path}/combined_ds/labels/{label}')\n",
    "            else:\n",
    "                shutil.copy(f'{path}/b_ds/{split}/labels/{label}', f'{path}/combined_ds/labels/{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(useCLAHE = False):\n",
    "    # images are already resized to 512x512\n",
    "    # apply CLAHE to images\n",
    "\n",
    "    for img in os.listdir(f'{path}/combined_ds/images'):\n",
    "        image = cv2.imread(f'{path}/combined_ds/images/{img}', cv2.IMREAD_GRAYSCALE) # need to convert to grayscale\n",
    "        if useCLAHE:\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            image = clahe.apply(image)\n",
    "        cv2.imwrite(f'{path}/combined_ds/images/{img}', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    vert_flip_image = cv2.flip(image, 0) # vertical flip\n",
    "\n",
    "    # cv2.imwrite(, image)\n",
    "\n",
    "    # augment label\n",
    "    # with open(path + f\"/org_ds/labels/{f'{real_name}_{names_with_freqs[numval]}_aug'}.txt\", \"w\") as file:\n",
    "    #     file.write(f\"{asdf} {1-float(file.readline().split(' ')[1])} {file.readline().split(' ')[2]} {file.readline().split(' ')[3]} {file.readline().split(' ')[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_to_names(backgrounds=0.1, augment=0):\n",
    "    \n",
    "    names_with_freqs = [0 for i in range(len(names))]\n",
    "    x=0\n",
    "\n",
    "    for name in names:\n",
    "        if os.path.exists(path + f\"/org_ds/{name}\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/{name}\")\n",
    "        os.makedirs(path + f\"/org_ds/{name}\")\n",
    "    \n",
    "    if os.path.exists(path + f\"/org_ds/labels\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/labels\")\n",
    "    os.makedirs(path + f\"/org_ds/labels\")\n",
    "\n",
    "    if backgrounds > 0:\n",
    "        if os.path.exists(path + f\"/org_ds/backgrounds\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/backgrounds\")\n",
    "        os.makedirs(path + f\"/org_ds/backgrounds\")\n",
    "    \n",
    "    for label in os.listdir(path + \"/combined_ds/labels\"):\n",
    "        # organize everything into folders based on\n",
    "        with open(path + f\"/combined_ds/labels/{label}\") as file:\n",
    "            # read first line\n",
    "            asdf = file.readline().split(\" \")[0]\n",
    "            # print(asdf)\n",
    "            try:\n",
    "                numval = int(asdf)\n",
    "                real_name = names[numval]\n",
    "                \n",
    "                # move image and label to folder\n",
    "                names_with_freqs[numval] += 1\n",
    "                \n",
    "                name, extension = os.path.splitext(label)\n",
    "                # assume that the file is already in jpg form\n",
    "                name = name[:name.rfind('_')]+'.jpg'\n",
    "                # print(name)\n",
    "                if not name in cannot_use:\n",
    "                    shutil.copy(path + f\"/combined_ds/images/{label[:-4]}.jpg\", path + f\"/org_ds/{real_name}/{real_name}_{names_with_freqs[numval]}.jpg\")\n",
    "                    shutil.copy(path + f\"/combined_ds/labels/{label}\", path + f\"/org_ds/labels/{real_name}_{names_with_freqs[numval]}.txt\")\n",
    "\n",
    "                    curr_name = f'{real_name}_{names_with_freqs[numval]}'\n",
    "                    if augment > 0:\n",
    "                        augment_image(curr_name)\n",
    "                        \n",
    "                    x+=1\n",
    "                else:\n",
    "                    print(f\"{name} is copyrighted, cannot be used\")\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if backgrounds > 0:\n",
    "        wanted_backgrounds = int(backgrounds * x)/(1-backgrounds)\n",
    "        print(f\"Total number of images: {x}\")\n",
    "        print(f\"Total number of backgrounds: {wanted_backgrounds}\")\n",
    "        \n",
    "        # get names of all files in Bacteria Dataset\n",
    "        \n",
    "        lab_images = []\n",
    "        for folder in os.listdir(path + \"/Bacteria Dataset/Dataset-1\"):\n",
    "            if os.path.isfile(folder) or (folder in names):\n",
    "                continue\n",
    "            for file in os.listdir(path + \"/Bacteria Dataset/Dataset-1/\" + folder):\n",
    "                if file == \".DS_Store\":\n",
    "                    continue\n",
    "                \n",
    "                lab_images.append(file)\n",
    "                name, extension = os.path.splitext(file)\n",
    "                # assume that the file is already in jpg form\n",
    "\n",
    "                image = cv2.imread(path + f\"/Bacteria Dataset/Dataset-1/{folder}/{file}\")\n",
    "                image = cv2.resize(image, (512, 512))\n",
    "                cv2.imwrite(path + f\"/Bacteria Dataset/Dataset-1/{folder}/{file}\", image)\n",
    "\n",
    "                # send to backgrounds folder\n",
    "                shutil.copy(path + f\"/Bacteria Dataset/Dataset-1/{folder}/{file}\", path + f\"/org_ds/backgrounds/{name}_background{extension}\")\n",
    "\n",
    "\n",
    "        for folder in os.listdir(path + \"/Bacteria Dataset/Dataset-2\"):\n",
    "            if os.path.isfile(folder) or (folder in names):\n",
    "                continue\n",
    "                \n",
    "            for file in os.listdir(path + \"/Bacteria Dataset/Dataset-2/\" + folder):\n",
    "                if file == \".DS_Store\":\n",
    "                    continue\n",
    "\n",
    "                lab_images.append(file)\n",
    "                name, extension = os.path.splitext(file)\n",
    "\n",
    "                # resize path + f\"/Bacteria Dataset/Dataset-2/{folder}/{file}\" to 512x512\n",
    "                image = cv2.imread(path + f\"/Bacteria Dataset/Dataset-2/{folder}/{file}\")\n",
    "                image = cv2.resize(image, (512, 512))\n",
    "                cv2.imwrite(path + f\"/Bacteria Dataset/Dataset-2/{folder}/{file}\", image)\n",
    "                # send to backgrounds folder\n",
    "                shutil.copy(path + f\"/Bacteria Dataset/Dataset-2/{folder}/{file}\", path + f\"/org_ds/backgrounds/{name}_background{extension}\")\n",
    "\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(lab_images)\n",
    "\n",
    "        lab_images = lab_images[:int(wanted_backgrounds)]\n",
    "        print(len(lab_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globftrain = 0\n",
    "globfvalid = 0\n",
    "globftest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_splits(include_backgrounds=False):\n",
    "    path = os.getcwd()\n",
    "\n",
    "    ftrain, fval, ftest = np.array([]), np.array([]), np.array([])\n",
    "    # stratify splitting of data\n",
    "    print(\"getting splits\")\n",
    "    for name in names:\n",
    "        allFileNames = os.listdir(path + f\"/org_ds/{name}\")\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(allFileNames)\n",
    "\n",
    "        train, val, test = np.split(np.array(allFileNames),[int(len(allFileNames)*0.8), int(len(allFileNames)*0.9)])\n",
    "\n",
    "        ftrain = np.concatenate((ftrain, train))\n",
    "        fval = np.concatenate((fval, val))\n",
    "        ftest = np.concatenate((ftest, test))\n",
    "\n",
    "        print(name, len(train), len(val), len(test))\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_backgrounds:\n",
    "        allFileNames = os.listdir(path + f\"/org_ds/backgrounds\")\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(allFileNames)\n",
    "\n",
    "        train, val, test = np.split(np.array(allFileNames),[int(len(allFileNames)*0.8), int(len(allFileNames)*0.9)])\n",
    "\n",
    "        ftrain = np.concatenate((ftrain, train))\n",
    "        fval = np.concatenate((fval, val))\n",
    "        ftest = np.concatenate((ftest, test))\n",
    "\n",
    "    print(\"final lengths after stratified split: \", len(ftrain), len(fval), len(ftest))\n",
    "    \n",
    "    global globftrain\n",
    "    global globfval\n",
    "    global globftest\n",
    "    globftrain = ftrain\n",
    "    globfval = fval\n",
    "    globftest = ftest\n",
    "    \n",
    "    return ftrain, fval, ftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_freqs(ftrain, fval, ftest):\n",
    "    splits = [ftrain, fval, ftest]\n",
    "    print(\"printing frequency information\")\n",
    "    print(len(ftrain), len(fval), len(ftest))\n",
    "    print(len(ftrain)/(len(ftrain)+len(fval)+len(ftest)))\n",
    "    splitarr = ['train', 'val', 'test']\n",
    "    # dictionary storing percentage frequencies across splits\n",
    "    freqs = {}\n",
    "    for name in names:\n",
    "        freqs[name] = [0,0,0]\n",
    "    \n",
    "    freqs[\"background\"] = [0,0,0]\n",
    "\n",
    "    print(\"total dataset size: \", len(ftrain)+len(fval)+len(ftest))\n",
    "    for i in range(len(splits)):\n",
    "        for name in names:\n",
    "            for file in splits[i]:\n",
    "                if name in file:\n",
    "                    freqs[name][i] += 1\n",
    "    \n",
    "    for name in names:\n",
    "        for i in range(len(freqs[name])):\n",
    "            print(name, splitarr[i], freqs[name][i]/sum(freqs[name]), freqs[name][i])\n",
    "        \n",
    "        # print total number of images\n",
    "        print(f\"total number of {name}: \", sum(freqs[name]))\n",
    "\n",
    "    print(\"background frequencies\")\n",
    "    # check background frequencies\n",
    "    for i in range(len(splits)):\n",
    "        for file in splits[i]:\n",
    "            if \"background\" in file:\n",
    "                freqs[\"background\"][i] += 1\n",
    "\n",
    "    for i in range(len(freqs[\"background\"])):\n",
    "        print(\"background\", splitarr[i], freqs[\"background\"][i]/sum(freqs[\"background\"]), freqs[\"background\"][i])\n",
    "\n",
    "    print(\"total background images\", sum(freqs[\"background\"]))\n",
    "    # print proportion of background images\n",
    "    print(\"proportion of background images: \", sum(freqs[\"background\"])/(len(ftrain)+len(fval)+len(ftest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_to_final(ftrain, fval, ftest):\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    \n",
    "    # clear existing final ds\n",
    "    if os.path.exists(path + \"/final_ds\"):\n",
    "        shutil.rmtree(path + \"/final_ds\")\n",
    "    os.mkdir(path + \"/final_ds\")\n",
    "    \n",
    "    for split in splits:\n",
    "        os.mkdir(path + f\"/final_ds/{split}\")\n",
    "        os.mkdir(path + f\"/final_ds/{split}/images\")\n",
    "        os.mkdir(path + f\"/final_ds/{split}/labels\")\n",
    "        \n",
    "        if split == 'train':\n",
    "            thing = ftrain\n",
    "        elif split == 'valid':\n",
    "            thing = fval\n",
    "        elif split == 'test':\n",
    "            thing = ftest\n",
    "        \n",
    "        for file in thing:\n",
    "            c = file.split(\"_\")[0] # class name\n",
    "            \n",
    "            if os.path.exists(path + f\"/org_ds/labels/{file[:-4]}.txt\"):\n",
    "                shutil.copy(path + f\"/org_ds/labels/{file[:-4]}.txt\", path + f\"/final_ds/{split}/labels/{file[:-4]}.txt\")\n",
    "                shutil.copy(path + f\"/org_ds/{c}/{file}\", path + f\"/final_ds/{split}/images/{file}\")\n",
    "            elif os.path.exists(path + f\"/org_ds/backgrounds/{file}\"):\n",
    "                shutil.copy(path + f\"/org_ds/backgrounds/{file}\", path + f\"/final_ds/{split}/images/{file}\")\n",
    "            \n",
    "\n",
    "\n",
    "    # add data.yaml file\n",
    "    with open(path + \"/final_ds/data.yaml\", \"w\") as file:\n",
    "        file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"aphanizomenon-88539393-original_jpg.rf.9fa1e6ed949dae36fb066abackground.jpg\"\n",
    "secondPart = s.split(\".\")[-2]\n",
    "print(secondPart[len(secondPart)-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_dataset(**kwargs):\n",
    "    useCLAHE = kwargs.get('useCLAHE', False)\n",
    "    augmentImages = kwargs.get('augment', 0)\n",
    "    backgrounds = kwargs.get('backgrounds', 0.1)\n",
    "\n",
    "    move_to_combined()\n",
    "\n",
    "    preprocess(useCLAHE = useCLAHE)\n",
    "    \n",
    "    organize_to_names(backgrounds, augment=augmentImages)\n",
    "    \n",
    "    ftrain, fval, ftest = get_train_val_test_splits(include_backgrounds = (backgrounds > 0))\n",
    "    # check_freqs(ftrain, fval, ftest)\n",
    "    print(fval)\n",
    "    print(ftest)\n",
    "    \n",
    "    reorganize_to_final(ftrain, fval, ftest)\n",
    "    # send to zip\n",
    "    shutil.make_archive(\"final_ds\", 'zip', path + \"/final_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 030322Planktothrix_GHT3_031122-40X_jpg.rf.17da996a5f726ba5d2b9ffe62258c547.jpg\n",
    "rebalance_dataset(useCLAHE=True, backgrounds=0.1)\n",
    "# print(len(os.listdir(path + \"/final_ds/train/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/valid/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/test/images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('images/aphanizomenon')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(os.listdir(path + \"/final_ds/train/labels\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/valid/labels\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/test/labels\")))\n",
    "\n",
    "# check if all labels have corresponding images\n",
    "for label in os.listdir(path + \"/final_ds/train/labels\"):\n",
    "    with open(path + f\"/final_ds/train/labels/{label}\") as file:\n",
    "        if len(file.readlines()) == 0:\n",
    "            print(label)\n",
    "    if not os.path.exists(path + f\"/final_ds/train/images/{label[:-4]}.jpg\"):\n",
    "        print(label)\n",
    "\n",
    "for label in os.listdir(path + \"/final_ds/valid/labels\"):\n",
    "    with open(path + f\"/final_ds/valid/labels/{label}\") as file:\n",
    "        if len(file.readlines()) == 0:\n",
    "            print(label)\n",
    "    if not os.path.exists(path + f\"/final_ds/valid/images/{label[:-4]}.jpg\"):\n",
    "        print(label)\n",
    "\n",
    "for label in os.listdir(path + \"/final_ds/test/labels\"):\n",
    "    with open(path + f\"/final_ds/test/labels/{label}\") as file:\n",
    "        if len(file.readlines()) == 0:\n",
    "            print(label)\n",
    "    if not os.path.exists(path + f\"/final_ds/test/images/{label[:-4]}.jpg\"):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_freqs(globftrain, globfval, globftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(path + \"/final_ds/train/images\")) + len(os.listdir(path + \"/final_ds/valid/images\")) + len(os.listdir(path + \"/final_ds/test/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/valid/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/test/images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of images from Bacteria Dataset folder that are in train, val, test of final_ds\n",
    "dict_trainvaltest = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "\n",
    "for file in globftrain:\n",
    "    if \"default\" in file:\n",
    "        dict_trainvaltest[\"train\"] += 1\n",
    "\n",
    "for file in globfval:\n",
    "    if \"default\" in file:\n",
    "        dict_trainvaltest[\"val\"] += 1   \n",
    "\n",
    "for file in globftest:\n",
    "    if \"default\" in file:\n",
    "        dict_trainvaltest[\"test\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_trainvaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare CLAHE vs no CLAHE\n",
    "image = cv2.imread(f'b_ds/train/images/113466794-medium_jpeg.rf.2d09325e3a8b7a92660be0f29ed856f7.jpg', cv2.IMREAD_GRAYSCALE) # need to convert to grayscale\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "clahe_image = clahe.apply(image)\n",
    "\n",
    "clahe_grid = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16,16))\n",
    "clahe_grid_image = clahe_grid.apply(image)\n",
    "\n",
    "# display original and CLAHE-ed images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(clahe_image, cmap='gray')\n",
    "ax[1].set_title('CLAHE')\n",
    "ax[2].imshow(clahe_grid_image, cmap='gray')\n",
    "ax[2].set_title('CLAHE Grid')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# save CLAHE-ed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(path + \"/final_ds/train/images\")))\n",
    "print(len(os.listdir(path + \"/final_ds/valid/images\")))\n",
    "print(len(os.listdir(path + \"/final_ds/test/images\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5bdfdf4a94b9d78a182717dc0316f3be25f7fd9c7cebd817f0c3b8d29721d43f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
