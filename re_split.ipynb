{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "names = ['aphanizomenon', 'detritus', 'dolichospermum', 'microcystis', 'oscillatoria', 'water bubble', 'woronichinia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree('b_ds', 'b_ds_copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset b_ds\n",
    "\n",
    "shutil.rmtree('b_ds')\n",
    "shutil.copytree('b_ds_copy', 'b_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data.yaml from b_ds\n",
    "with open('b_ds/data.yaml', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# remove everything after \"roboflow\"\n",
    "data = data.split('roboflow')[0] # this will be the same...\n",
    "\n",
    "# get all names from data.yaml\n",
    "names = data.split('names: ')[1]\n",
    "\n",
    "# convert string names to list\n",
    "names = eval(names)\n",
    "print(names)\n",
    "\n",
    "# rewrite train, val, test to go to final_ds/{split}/images instead of ../{split}/images\n",
    "data = data.replace('../train/images', 'final_ds/train/images')\n",
    "data = data.replace('../valid/images', 'final_ds/valid/images')\n",
    "data = data.replace('../test/images', 'final_ds/test/images')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all background images from b_ds\n",
    "for split in os.listdir('b_ds'):\n",
    "    if split == 'train' or split == 'valid' or split == 'test':\n",
    "        for filename in os.listdir(f'b_ds/{split}/images'):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if 'background' in filename:\n",
    "                os.remove(f'b_ds/{split}/images/{filename}')\n",
    "                os.remove(f'b_ds/{split}/labels/{filename[:-4]}.txt')\n",
    "\n",
    "print(len(os.listdir('b_ds/train/images')) + len(os.listdir('b_ds/valid/images')) + len(os.listdir('b_ds/test/images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree('b_ds')\n",
    "# shutil.copytree('b_ds_copy', 'b_ds')\n",
    "# clean up roboflow imported dataset\n",
    "\n",
    "def clean_roboflow_dataset():\n",
    "    # get index of \"_jpg\" \n",
    "    names = ['aphanizomenon', 'detritus', 'dolichospermum', 'microcystis', 'oscillatoria', 'water bubble', 'woronichinia']\n",
    "    for split in os.listdir('b_ds'):\n",
    "        if split == 'test' or split == 'train' or split == 'valid':\n",
    "            print(split)\n",
    "            for image in os.listdir(f'b_ds/{split}/images'):\n",
    "                # rename image at this path to remove \"_jpg\"\n",
    "                # get index of \"_jpg\"\n",
    "                name, ext = os.path.splitext(image)\n",
    "                # b_ds/test/images/woronichinia-259918842-original_jpg.rf.6aa07c318a25214c7d100b271443c1d6.jpg\n",
    "                new_image = image[:image.rfind('_')] + ext\n",
    "                # replace current image with new image\n",
    "                # get image path\n",
    "\n",
    "                label = image[:-4] + '.txt'\n",
    "                os.rename(f'b_ds/{split}/images/{image}', f'b_ds/{split}/images/{new_image}')\n",
    "                os.rename(f'b_ds/{split}/labels/{label}', f'b_ds/{split}/labels/{new_image[:-4]}.txt')\n",
    "\n",
    "                found = False\n",
    "                for comp_name in names:\n",
    "                    if comp_name.lower() in new_image.lower():\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    # this is for lab images that do not have the name associated to it\n",
    "                    \n",
    "                    # retrieve label from corresponding txt file\n",
    "                    if os.path.exists(f'b_ds/{split}/labels/{new_image[:-4]}.txt'):   \n",
    "                        with open(f'b_ds/{split}/labels/{new_image[:-4]}.txt', 'r') as f:\n",
    "                            label = f.read()\n",
    "                            if len(label) > 0:\n",
    "                                label = int(label.split(' ')[0])\n",
    "                                print(new_image, label)\n",
    "                                # copy image to corresponding folder\n",
    "                                os.rename(f'b_ds/{split}/images/{new_image}', f'b_ds/{split}/images/{names[label]}-{new_image}')\n",
    "                                # copy label to corresponding folder\n",
    "                                os.rename(f'b_ds/{split}/labels/{new_image[:-4]}.txt', f'b_ds/{split}/labels/{names[label]}-{new_image[:-4]}.txt')\n",
    "clean_roboflow_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_incorrect_labels():\n",
    "    for split in os.listdir('b_ds'):\n",
    "        if split == 'train' or split == 'valid' or split == 'test':\n",
    "            for image in os.listdir(f'b_ds/{split}/images'):\n",
    "                matches = False\n",
    "                for name in names:\n",
    "                    if name.lower() in image.lower():\n",
    "                        if not os.path.exists(f'b_ds/{split}/labels/{image[:-4]}.txt'):\n",
    "                            continue\n",
    "                        with open(f'b_ds/{split}/labels/{image[:-4]}.txt', 'r') as f:\n",
    "                            data = f.read()\n",
    "                            if len(data) == 0:\n",
    "                                continue\n",
    "                            data = int(data.split(' ')[0])\n",
    "\n",
    "                            if names[data] == name:\n",
    "                                matches = True\n",
    "                                break\n",
    "                \n",
    "                if not matches:\n",
    "                    print(split, image)\n",
    "\n",
    "check_for_incorrect_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_folders():\n",
    "    shutil.rmtree(path + \"/combined_ds\")\n",
    "    shutil.rmtree(path + \"/org_ds\")\n",
    "    shutil.rmtree(path + \"/final_ds\")\n",
    "try:\n",
    "    delete_all_folders()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = ['test', 'train', 'valid']\n",
    "\n",
    "for split in splits:\n",
    "        for img in os.listdir(f'{path}/b_ds/{split}/images'):\n",
    "                if \"0911191156c\" in img:\n",
    "                        print(img, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_combined(exclude_classes = ['anabaena']):\n",
    "    splits = ['test', 'train', 'valid']\n",
    "\n",
    "    if os.path.exists(path + f\"/combined_ds\"):\n",
    "        shutil.rmtree(path + f\"/combined_ds\")\n",
    "    os.mkdir(path + f\"/combined_ds\")\n",
    "    os.mkdir(path + f\"/combined_ds/images\")\n",
    "    os.mkdir(path + f\"/combined_ds/labels\")\n",
    "\n",
    "    # \n",
    "    seen = []\n",
    "    for split in splits:\n",
    "        for img in os.listdir(f'{path}/b_ds/{split}/images'):\n",
    "            if len(exclude_classes) > 0:\n",
    "                for exclude_class in exclude_classes:\n",
    "                    if not exclude_class in img:\n",
    "                        shutil.copy(f'{path}/b_ds/{split}/images/{img}', f'{path}/combined_ds/images/{img}')\n",
    "            else:\n",
    "                shutil.copy(f'{path}/b_ds/{split}/images/{img}', f'{path}/combined_ds/images/{img}')\n",
    "        for label in os.listdir(f'{path}/b_ds/{split}/labels'):\n",
    "            if len(exclude_classes) > 0:\n",
    "                for exclude_class in exclude_classes:            \n",
    "                    if not exclude_class in label:\n",
    "                        shutil.copy(f'{path}/b_ds/{split}/labels/{label}', f'{path}/combined_ds/labels/{label}')\n",
    "            else:\n",
    "                shutil.copy(f'{path}/b_ds/{split}/labels/{label}', f'{path}/combined_ds/labels/{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(useCLAHE = False, grayscale = False):\n",
    "    # images are already resized to 512x512\n",
    "    # apply CLAHE to images\n",
    "    for split in os.listdir(f'b_ds'):\n",
    "        if split == 'train' or split == 'test' or split == 'valid':\n",
    "            for img_path in os.listdir(f'b_ds/{split}/images'):\n",
    "                \n",
    "                if useCLAHE:\n",
    "                    if not grayscale:\n",
    "                        image = cv2.imread(f'b_ds/{split}/images/{img_path}')\n",
    "                        image = cv2.resize(image, (512, 512))\n",
    "                        lab = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), cv2.COLOR_BGR2LAB)\n",
    "                        lab_planes = list(cv2.split(lab))\n",
    "                        \n",
    "                        clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(32,32))\n",
    "                        lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "                        lab = cv2.merge(tuple(lab_planes))\n",
    "                        bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "                        image = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "                    else:\n",
    "                        image = cv2.imread(f'b_ds/{split}/images/{img_path}', cv2.IMREAD_GRAYSCALE)\n",
    "                        image = cv2.resize(image, (512, 512))\n",
    "                        clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(32,32))\n",
    "                        image = clahe.apply(image)\n",
    "\n",
    "                cv2.imwrite(f'{path}/combined_ds/images/{img_path}', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_to_names(backgrounds=0.1, augment=0):\n",
    "    with open('licenses.json') as f:\n",
    "        licenses = json.load(f)\n",
    "        cannot_use = set([])\n",
    "        for l, vals in licenses.items():\n",
    "            if l == 'null':\n",
    "                for name, imgs in licenses[l].items():\n",
    "                    for img_name, url in imgs.items():\n",
    "                        cannot_use.add(img_name)\n",
    "\n",
    "    names_with_freqs = [0 for i in range(len(names))]\n",
    "    x=0\n",
    "    if os.path.exists(path + f\"/org_ds\"):\n",
    "        shutil.rmtree(path + f\"/org_ds\")\n",
    "    os.mkdir(path + f\"/org_ds\")\n",
    "    for name in names:\n",
    "        if os.path.exists(path + f\"/org_ds/{name}\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/{name}\")\n",
    "        os.makedirs(path + f\"/org_ds/{name}\")\n",
    "    \n",
    "    if os.path.exists(path + f\"/org_ds/labels\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/labels\")\n",
    "    os.makedirs(path + f\"/org_ds/labels\")\n",
    "\n",
    "    if backgrounds > 0:\n",
    "        if os.path.exists(path + f\"/org_ds/backgrounds\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/backgrounds\")\n",
    "        os.makedirs(path + f\"/org_ds/backgrounds\")\n",
    "    \n",
    "    for label in os.listdir(path + \"/combined_ds/labels\"):\n",
    "        # organize everything into folders based on\n",
    "        if not os.path.exists(path + f\"/combined_ds/labels/{label}\"):\n",
    "            print(label, \"does not exist\")\n",
    "            continue\n",
    "        with open(path + f\"/combined_ds/labels/{label}\") as file:\n",
    "            # read first line\n",
    "            asdf = file.readline()\n",
    "            if len(asdf) == 0:\n",
    "                print(label, \"is empty\")\n",
    "                continue\n",
    "            \n",
    "            asdf = asdf.split(\" \")[0]\n",
    "            # print(asdf)\n",
    "            numval = int(asdf)\n",
    "            real_name = names[numval]\n",
    "            \n",
    "            # move image and label to folder\n",
    "            names_with_freqs[numval] += 1\n",
    "            \n",
    "            name, extension = os.path.splitext(label)\n",
    "            # assume that the file is already in jpg form\n",
    "            if not name in cannot_use:\n",
    "                print(name)\n",
    "                shutil.copy(path + f\"/combined_ds/images/{label[:-4]}.jpg\", path + f\"/org_ds/{real_name}/{name}.jpg\")\n",
    "                shutil.copy(path + f\"/combined_ds/labels/{label}\", path + f\"/org_ds/labels/{name}.txt\")\n",
    "\n",
    "                # if augment > 0:\n",
    "                #     augment_image(curr_name)\n",
    "                    \n",
    "                x+=1\n",
    "            else:\n",
    "                print(f\"{name} is copyrighted, cannot be used\")\n",
    "    \n",
    "    if backgrounds > 0:\n",
    "        wanted_backgrounds = int(backgrounds * x)/(1-backgrounds)\n",
    "        print(f\"Total number of images: {x}\")\n",
    "        print(f\"Total number of backgrounds: {wanted_backgrounds}\")\n",
    "        \n",
    "        # get names of all files in Bacteria Dataset\n",
    "        \n",
    "        lab_images = []\n",
    "        for folder in os.listdir(path + \"/Bacteria Dataset/Dataset-1\"):\n",
    "            if os.path.isfile(folder) or (folder in names) or folder == \"FlowCam Library 2021\" or folder == \"FlowCam Library Instructions.docx\":\n",
    "                continue\n",
    "            for file in os.listdir(path + \"/Bacteria Dataset/Dataset-1/\" + folder):\n",
    "                if file == \".DS_Store\":\n",
    "                    continue\n",
    "                \n",
    "                lab_images.append(file)\n",
    "                name, extension = os.path.splitext(file)\n",
    "                # assume that the file is already in jpg form\n",
    "                image = cv2.imread(path + \"/Bacteria Dataset/Dataset-1/\" + folder + \"/\" + file)\n",
    "                try:\n",
    "                    image = cv2.resize(image, (512, 512))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"Could not resize {file}\")\n",
    "                    0/0\n",
    "                    continue\n",
    "                lab = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), cv2.COLOR_BGR2LAB)\n",
    "                lab_planes = list(cv2.split(lab))\n",
    "                \n",
    "                clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(32,32))\n",
    "                lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "                lab = cv2.merge(tuple(lab_planes))\n",
    "                bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "                image = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                cv2.imwrite(f'{path}/org_ds/backgrounds/{name}_background.jpg', image)\n",
    "\n",
    "\n",
    "        for folder in os.listdir(path + \"/Bacteria Dataset/Dataset-2\"):\n",
    "            if os.path.isfile(folder) or (folder in names) or folder == \"FlowCam Library 2021\" or folder == \"FlowCam Library Instructions.docx\":\n",
    "                continue\n",
    "                \n",
    "            for file in os.listdir(path + \"/Bacteria Dataset/Dataset-2/\" + folder):\n",
    "                if file == \".DS_Store\":\n",
    "                    continue\n",
    "\n",
    "                lab_images.append(file)\n",
    "                name, extension = os.path.splitext(file)\n",
    "\n",
    "                image = cv2.imread(path + \"/Bacteria Dataset/Dataset-2/\" + folder + \"/\" + file)\n",
    "                \n",
    "                image = cv2.resize(image, (512, 512))\n",
    "                lab = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), cv2.COLOR_BGR2LAB)\n",
    "                lab_planes = list(cv2.split(lab))\n",
    "                \n",
    "                clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(32,32))\n",
    "                lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "                lab = cv2.merge(tuple(lab_planes))\n",
    "                bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "                image = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                cv2.imwrite(f'{path}/org_ds/backgrounds/{name}_background.jpg', image)\n",
    "\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(lab_images)\n",
    "\n",
    "        lab_images = lab_images[:int(wanted_backgrounds)]\n",
    "        print(len(lab_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globftrain = 0\n",
    "globfvalid = 0\n",
    "globftest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_splits(include_backgrounds=False):\n",
    "    path = os.getcwd()\n",
    "\n",
    "    ftrain, fval, ftest = np.array([]), np.array([]), np.array([])\n",
    "    # stratify splitting of data\n",
    "    print(\"getting splits\")\n",
    "    for name in names:\n",
    "        allFileNames = os.listdir(path + f\"/org_ds/{name}\")\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(allFileNames)\n",
    "\n",
    "        train, val, test = np.split(np.array(allFileNames),[int(len(allFileNames)*0.8), int(len(allFileNames)*0.9)])\n",
    "\n",
    "        ftrain = np.concatenate((ftrain, train))\n",
    "        fval = np.concatenate((fval, val))\n",
    "        ftest = np.concatenate((ftest, test))\n",
    "\n",
    "        print(name, len(train), len(val), len(test))\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_backgrounds:\n",
    "        allFileNames = os.listdir(path + f\"/org_ds/backgrounds\")\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(allFileNames)\n",
    "\n",
    "        train, val, test = np.split(np.array(allFileNames),[int(len(allFileNames)*0.8), int(len(allFileNames)*0.9)])\n",
    "\n",
    "        ftrain = np.concatenate((ftrain, train))\n",
    "        fval = np.concatenate((fval, val))\n",
    "        ftest = np.concatenate((ftest, test))\n",
    "\n",
    "    print(\"final lengths after stratified split: \", len(ftrain), len(fval), len(ftest))\n",
    "    \n",
    "    global globftrain\n",
    "    global globfval\n",
    "    global globftest\n",
    "    globftrain = ftrain\n",
    "    globfval = fval\n",
    "    globftest = ftest\n",
    "    \n",
    "    return ftrain, fval, ftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_freqs(ftrain, fval, ftest):\n",
    "    splits = [ftrain, fval, ftest]\n",
    "    print(\"printing frequency information\")\n",
    "    print(len(ftrain), len(fval), len(ftest))\n",
    "    print(len(ftrain)/(len(ftrain)+len(fval)+len(ftest)))\n",
    "    splitarr = ['train', 'val', 'test']\n",
    "    # dictionary storing percentage frequencies across splits\n",
    "    freqs = {}\n",
    "    for name in names:\n",
    "        freqs[name] = [0,0,0]\n",
    "    \n",
    "    freqs[\"background\"] = [0,0,0]\n",
    "\n",
    "    print(\"total dataset size: \", len(ftrain)+len(fval)+len(ftest))\n",
    "    for i in range(len(splits)):\n",
    "        for name in names:\n",
    "            for file in splits[i]:\n",
    "                if name in file:\n",
    "                    freqs[name][i] += 1\n",
    "    \n",
    "    for name in names:\n",
    "        for i in range(len(freqs[name])):\n",
    "            print(name, splitarr[i], freqs[name][i]/sum(freqs[name]), freqs[name][i])\n",
    "        \n",
    "        # print total number of images\n",
    "        print(f\"total number of {name}: \", sum(freqs[name]))\n",
    "\n",
    "    print(\"background frequencies\")\n",
    "    # check background frequencies\n",
    "    for i in range(len(splits)):\n",
    "        for file in splits[i]:\n",
    "            if \"background\" in file:\n",
    "                freqs[\"background\"][i] += 1\n",
    "\n",
    "    for i in range(len(freqs[\"background\"])):\n",
    "        print(\"background\", splitarr[i], freqs[\"background\"][i]/sum(freqs[\"background\"]), freqs[\"background\"][i])\n",
    "\n",
    "    print(\"total background images\", sum(freqs[\"background\"]))\n",
    "    # print proportion of background images\n",
    "    print(\"proportion of background images: \", sum(freqs[\"background\"])/(len(ftrain)+len(fval)+len(ftest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_freqs_dir(base = \"final_ds\"):\n",
    "    splits = [os.listdir(f'{base}/train/images'), os.listdir(f'{base}/valid/images'), os.listdir(f'{base}/test/images')]\n",
    "    print(\"printing frequency information\")\n",
    "    trainlen, vallen, testlen = len(os.listdir(f'{base}/train/images')), len(os.listdir(f'{base}/valid/images')), len(os.listdir(f'{base}/test/images'))\n",
    "    print(trainlen, vallen, testlen)\n",
    "    print(\"total dataset size: \", trainlen + vallen + testlen)\n",
    "\n",
    "    splitarr = ['train', 'valid', 'test']\n",
    "    # dictionary storing percentage frequencies across splits\n",
    "    freqs = {}\n",
    "    for name in names:\n",
    "        freqs[name] = [0,0,0]\n",
    "    \n",
    "    freqs[\"background\"] = [0,0,0]\n",
    "\n",
    "    \n",
    "    for i in range(len(splits)):\n",
    "        for name in names:\n",
    "            for file in splits[i]:\n",
    "                if name.lower() in file.lower():\n",
    "                    freqs[name][i] += 1\n",
    "    print(\"background frequencies\")\n",
    "    # check background frequencies\n",
    "    for i in range(len(splits)):\n",
    "        for file in splits[i]:\n",
    "            if \"background\" in file:\n",
    "                freqs[\"background\"][i] += 1\n",
    "    \n",
    "    print(freqs)\n",
    "    \n",
    "    for name in names:\n",
    "        if sum(freqs[name]) == 0:\n",
    "            continue\n",
    "        for i in range(len(freqs[name])):\n",
    "            print(name, splitarr[i], freqs[name][i]/sum(freqs[name]), freqs[name][i])\n",
    "        \n",
    "        # print total number of images\n",
    "        print(f\"total number of {name}: \", sum(freqs[name]))\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(len(freqs[\"background\"])):\n",
    "        if sum(freqs[\"background\"]) == 0:\n",
    "            continue\n",
    "        print(\"background\", splitarr[i], freqs[\"background\"][i]/sum(freqs[\"background\"]), freqs[\"background\"][i])\n",
    "\n",
    "    print(\"total background images\", sum(freqs[\"background\"]))\n",
    "    # print proportion of background images\n",
    "    print(\"proportion of background images: \", sum(freqs[\"background\"])/(trainlen+vallen+testlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_freqs_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_to_final(ftrain, fval, ftest):\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    \n",
    "    # clear existing final ds\n",
    "    if os.path.exists(path + \"/final_ds\"):\n",
    "        shutil.rmtree(path + \"/final_ds\")\n",
    "    os.mkdir(path + \"/final_ds\")\n",
    "    \n",
    "    for split in splits:\n",
    "        os.mkdir(path + f\"/final_ds/{split}\")\n",
    "        os.mkdir(path + f\"/final_ds/{split}/images\")\n",
    "        os.mkdir(path + f\"/final_ds/{split}/labels\")\n",
    "        \n",
    "        if split == 'train':\n",
    "            thing = ftrain\n",
    "        elif split == 'valid':\n",
    "            thing = fval\n",
    "        elif split == 'test':\n",
    "            thing = ftest\n",
    "        \n",
    "        for file in thing:\n",
    "            classname = None\n",
    "            for name in names:\n",
    "                if name.lower() in file.lower():\n",
    "                    classname = name\n",
    "                    print(classname)\n",
    "                    break\n",
    "            \n",
    "            if os.path.exists(path + f\"/org_ds/labels/{file[:-4]}.txt\"):\n",
    "                shutil.copy(path + f\"/org_ds/labels/{file[:-4]}.txt\", path + f\"/final_ds/{split}/labels/{file[:-4]}.txt\")\n",
    "                shutil.copy(path + f\"/org_ds/{classname}/{file}\", path + f\"/final_ds/{split}/images/{file}\")\n",
    "            elif os.path.exists(path + f\"/org_ds/backgrounds/{file}\"):\n",
    "                shutil.copy(path + f\"/org_ds/backgrounds/{file}\", path + f\"/final_ds/{split}/images/{file}\")\n",
    "            \n",
    "\n",
    "\n",
    "    # add data.yaml file\n",
    "    with open(path + \"/final_ds/data.yaml\", \"w\") as file:\n",
    "        file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"aphanizomenon-88539393-original_jpg.rf.9fa1e6ed949dae36fb066abackground.jpg\"\n",
    "secondPart = s.split(\".\")[-2]\n",
    "print(secondPart[len(secondPart)-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_dataset(**kwargs):\n",
    "    print(\"deleting folders\")\n",
    "    def delete_all_folders():\n",
    "        shutil.rmtree(path + \"/combined_ds\")\n",
    "        shutil.rmtree(path + \"/org_ds\")\n",
    "        shutil.rmtree(path + \"/final_ds\")\n",
    "    try:\n",
    "        delete_all_folders()\n",
    "    except:\n",
    "        pass\n",
    "    useCLAHE = kwargs.get('useCLAHE', False)\n",
    "    augmentImages = kwargs.get('augment', 0)\n",
    "    backgrounds = kwargs.get('backgrounds', 0.1)\n",
    "\n",
    "    print(\"moving everything to combined\")\n",
    "    move_to_combined()\n",
    "\n",
    "    print(\"preprocessing\")\n",
    "    preprocess(useCLAHE = useCLAHE)\n",
    "    \n",
    "    print(\"organizing to names\")\n",
    "\n",
    "    organize_to_names(backgrounds, augment=augmentImages)\n",
    "    \n",
    "    ftrain, fval, ftest = get_train_val_test_splits(include_backgrounds = (backgrounds > 0))\n",
    "    # check_freqs(ftrain, fval, ftest)\n",
    "    print(fval)\n",
    "    print(ftest)\n",
    "    \n",
    "    reorganize_to_final(ftrain, fval, ftest)\n",
    "    # send to zip\n",
    "    shutil.make_archive(\"final_ds\", 'zip', path + \"/final_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 030322Planktothrix_GHT3_031122-40X_jpg.rf.17da996a5f726ba5d2b9ffe62258c547.jpg\n",
    "rebalance_dataset(useCLAHE=True, backgrounds=0.1)\n",
    "# print(len(os.listdir(path + \"/final_ds/train/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/valid/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/test/images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in os.listdir('final_ds'):\n",
    "    if split == 'train' or split == 'test' or split == 'valid':\n",
    "        for file in os.listdir(f'final_ds/{split}/images'):\n",
    "            print(file)\n",
    "            if not \".jpg\" in file:\n",
    "                \n",
    "                print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('images/aphanizomenon')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(os.listdir(path + \"/final_ds/train/labels\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/valid/labels\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/test/labels\")))\n",
    "\n",
    "# check if all labels have corresponding images\n",
    "for label in os.listdir(path + \"/final_ds/train/labels\"):\n",
    "    with open(path + f\"/final_ds/train/labels/{label}\") as file:\n",
    "        if len(file.readlines()) == 0:\n",
    "            print(label)\n",
    "    if not os.path.exists(path + f\"/final_ds/train/images/{label[:-4]}.jpg\"):\n",
    "        print(label)\n",
    "\n",
    "for label in os.listdir(path + \"/final_ds/valid/labels\"):\n",
    "    with open(path + f\"/final_ds/valid/labels/{label}\") as file:\n",
    "        if len(file.readlines()) == 0:\n",
    "            print(label)\n",
    "    if not os.path.exists(path + f\"/final_ds/valid/images/{label[:-4]}.jpg\"):\n",
    "        print(label)\n",
    "\n",
    "for label in os.listdir(path + \"/final_ds/test/labels\"):\n",
    "    with open(path + f\"/final_ds/test/labels/{label}\") as file:\n",
    "        if len(file.readlines()) == 0:\n",
    "            print(label)\n",
    "    if not os.path.exists(path + f\"/final_ds/test/images/{label[:-4]}.jpg\"):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_freqs_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(path + \"/final_ds/train/images\")) + len(os.listdir(path + \"/final_ds/valid/images\")) + len(os.listdir(path + \"/final_ds/test/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/valid/images\")))\n",
    "# print(len(os.listdir(path + \"/final_ds/test/images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of images from Bacteria Dataset folder that are in train, val, test of final_ds\n",
    "dict_trainvaltest = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "\n",
    "for file in globftrain:\n",
    "    if \"default\" in file:\n",
    "        dict_trainvaltest[\"train\"] += 1\n",
    "\n",
    "for file in globfval:\n",
    "    if \"default\" in file:\n",
    "        dict_trainvaltest[\"val\"] += 1   \n",
    "\n",
    "for file in globftest:\n",
    "    if \"default\" in file:\n",
    "        dict_trainvaltest[\"test\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_trainvaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare CLAHE vs no CLAHE\n",
    "image = cv2.imread(f'b_ds/train/images/113466794-medium_jpeg.rf.2d09325e3a8b7a92660be0f29ed856f7.jpg', cv2.IMREAD_GRAYSCALE) # need to convert to grayscale\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "clahe_image = clahe.apply(image)\n",
    "\n",
    "clahe_grid = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16,16))\n",
    "clahe_grid_image = clahe_grid.apply(image)\n",
    "\n",
    "# display original and CLAHE-ed images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(clahe_image, cmap='gray')\n",
    "ax[1].set_title('CLAHE')\n",
    "ax[2].imshow(clahe_grid_image, cmap='gray')\n",
    "ax[2].set_title('CLAHE Grid')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# save CLAHE-ed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(path + \"/final_ds/train/images\")))\n",
    "print(len(os.listdir(path + \"/final_ds/valid/images\")))\n",
    "print(len(os.listdir(path + \"/final_ds/test/images\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5bdfdf4a94b9d78a182717dc0316f3be25f7fd9c7cebd817f0c3b8d29721d43f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
